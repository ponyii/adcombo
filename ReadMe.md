### Структура репозитория

`log_parser.py` - чтение единственного файла логов;
`dir_parser.py` - чтение всех логов в директории;
`generator.py` - генерация логов (для тестирования); с помощью этого модуля созданы все логи из папки test_files_generated (см. ниже);
`helpers.py` - всякая всячина, используемая в остальных модулях;
`bicycle.py` - ускорение обработки логов; DEPRECATED, см. комментарии в файле;
`tests.py` - тесты.


##### Автоматически сгенерированные логи

Среди них есть большие; если бы это был "настоящий" код, стоило бы создать отдельный репозиторий для больших тестовых данных или использовать другой способ избавить каждого пользователя модуля от необходимости их выкачивать; однако в проверочном задании кажется более удобным свалить все в одну кучу.


### Комментарий к заданию

"Верхняя" функция, решающая поставленную задачу, содержиться в `dir_parser.py`.
Задание: https://gist.github.com/onyxim/bb2d1828df741499d17ba97ad3319ef1


##### Касательно использования вычислительной мощности компьютера

Это не было отражено в `tests.py`, но я запускал парсинг директории с несколькими десятками сгенерированных логов (около 4-6 МБ каждый), и наблюдал полную загрузку обоих процессоров (если верить `htop`) и рост скорости примерно в 1,8 раз. Кажется, это стоит считать неулучшаемым результатом - я не смог придумать возможных проблем со взаимодействием потоков, не связанных с чтением файлов; но скорость аналогичных вычислений, но без чтения из файлов, растет примерно в те же 1,8 раз.


##### НЕ было сделано

Стоило запустить на ночь парсинг большого количества больших сгенерированных логов и убедится, что все работает. Сделать этого вчера вечером не успел; отправляю результат выполнения сейчас, и планирую запустить проверку на ближайшую ночь.

В файлах `bicycle.py` и `dir_parser.py` упомянуты некоторые изменения, про которые я не понимаю, стоит ли их вносить; я готов внести их после обсуждения, если потребуется.


##### Некоторые вопросы к заданию

Дублирую фрагмент переписки с @num_ex, содержащий вопросы по заданию и ответы на них.

```
Hides-His-Tail, [16.03.20 11:38]
<...>
0. Правда ли, что мне слеует использовать только Python? Требование оптимальности порождает желание написать хотя бы часть кода на чем-то более быстром.
1. Как следует работать с некорректными записями в логе?
Т.е. могут ли попадаться строки с, например, иным набором ключей или странной query_string? Или же следует считать, что проверка логов осуществляется в другом месте, и лог обязан состоять из валидных и невалидных \n-separated запросов?
2. Могу ли я считать, что query_string достаточно короткая?
3. Могу ли я получить информацию о числе ядер и скорости чтения с диска на машине, на которой код должен запускаться?
Такой проблемы не возникает на моем ноутбуке, но при чтении логов достаточно большим числом процессоров теоретически можно упереться в с.ч.; стоит ли мне беспокоиться об этом?
Хотя если честно, у меня пока не дошли руки погуглить конкретные значения и оценить, реальна ли такая проблема.
4. Следует ли мне следовать конкретному code policy или же исходить из своих представлений о прекрасном?
5. Могу ли я верить, что с файломи логов работаю только я, никакой другой процесс их не изменяет? Что в директории не появляются новые файлы логов?
6. Правда ли, что timestamp'ы как внутри лога, так и между файлами логов возрастают?
Такое предположение кажется естественным; из него следует, что стоит рассчитывать на очень большой словарь-результат - вероятно, достаточно большой, чтобы его стоило хранить во внешней памяти. Это правда?

Sergey, [16.03.20 12:47]
Приветствую!
0. Нужно использовать только Python для решения этой задачи.
1. предполагается второй вариант
2. достаточно коротка в терминах RFC? или в каком смысле?
3. при решении задачи можешь ориентироваться на максимальное использование ресурсов своего ноутбука
4. исходи из своих предпочтений о прекрасном
5. давай предположим, что новые файлы логов могут возникать (через ротацию логов раз в час), однако отротированные логи никто не правит
6. В задаче указано про группировку по дням. Даже если проект работает 10 лет, и по каждому дню есть записи, вряд ли это будет проблемой.

Hides-His-Tail, [16.03.20 12:52]
2. в смысле значительно меньше доступной процессу памяти; т.е. могу ли я продолжить считывать строки целиком или же стоит их фрагментировать.

Sergey, [16.03.20 12:52]
Cтроки можно считывать целиком. URL RFC валиден.
```
